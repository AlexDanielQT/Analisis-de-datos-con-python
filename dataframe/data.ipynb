{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIR LOS DATOS EN EL MISMO FORMATO DE SPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat  # Importa la librería pyreadstat para leer archivos .sav (SPSS)\n",
    "import pandas as pd  # Importa la librería pandas para manipulación y análisis de datos\n",
    "\n",
    "# Cargar los archivos .sav en DataFrames separados\n",
    "# Utiliza la función read_sav de la librería pyreadstat para leer los archivos .sav\n",
    "# Los resultados se guardan en dos variables: el DataFrame y la metadata del archivo .sav\n",
    "\n",
    "df_car_c, meta_car_c = pyreadstat.read_sav('01_PENALES_CARATULA.sav')  # Lee el archivo '01_PENALES_CARATULA.sav' y guarda los datos en df_car_c y la metadata en meta_car_c\n",
    "df_cap100, meta_cap100 = pyreadstat.read_sav('01_PENALES_CAP100.sav')  # Lee el archivo '01_PENALES_CAP100.sav' y guarda los datos en df_cap100 y la metadata en meta_cap100\n",
    "df_cap200, meta_cap200 = pyreadstat.read_sav('01_PENALES_CAP200.sav')  # Lee el archivo '01_PENALES_CAP200.sav' y guarda los datos en df_cap200 y la metadata en meta_cap200\n",
    "df_cap300, meta_cap300 = pyreadstat.read_sav('01_PENALES_CAP300.sav')  # Lee el archivo '01_PENALES_CAP300.sav' y guarda los datos en df_cap300 y la metadata en meta_cap300\n",
    "df_cap400, meta_cap400 = pyreadstat.read_sav('01_PENALES_CAP400.sav')  # Lee el archivo '01_PENALES_CAP400.sav' y guarda los datos en df_cap400 y la metadata en meta_cap400\n",
    "\n",
    "# Guardar cada DataFrame como archivo .csv\n",
    "# Utiliza la función to_csv del DataFrame de pandas para guardar los datos en archivos .csv\n",
    "# El parámetro index=False asegura que el índice de los DataFrames no se guarde en el archivo .csv\n",
    "\n",
    "df_car_c.to_csv('01_PENALES_CARATULA.csv', index=False)  # Guarda df_car_c en '01_PENALES_CARATULA.csv' sin incluir el índice\n",
    "df_cap100.to_csv('01_PENALES_CAP100.csv', index=False)  # Guarda df_cap100 en '01_PENALES_CAP100.csv' sin incluir el índice\n",
    "df_cap200.to_csv('01_PENALES_CAP200.csv', index=False)  # Guarda df_cap200 en '01_PENALES_CAP200.csv' sin incluir el índice\n",
    "df_cap300.to_csv('01_PENALES_CAP300.csv', index=False)  # Guarda df_cap300 en '01_PENALES_CAP300.csv' sin incluir el índice\n",
    "df_cap400.to_csv('01_PENALES_CAP400.csv', index=False)  # Guarda df_cap400 en '01_PENALES_CAP400.csv' sin incluir el índice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUNTAR ARCHIVOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos CSV combinados exitosamente en DATA1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "def main():\n",
    "    # Lista de archivos de entrada\n",
    "    input_files = [\"01_PENALES_CARATULA.csv\", \"01_PENALES_CAP100.csv\", \"01_PENALES_CAP200.csv\", \"01_PENALES_CAP300.csv\", \"01_PENALES_CAP400.csv\"]\n",
    "    # Archivo de salida\n",
    "    output_file = \"DATA1.csv\"\n",
    "\n",
    "    # Leer todos los archivos CSV en una lista de DataFrames\n",
    "    dataframes = []\n",
    "    for file in input_files:\n",
    "        try:\n",
    "            # Intentar leer el archivo CSV\n",
    "            df = pd.read_csv(file, encoding='utf-8', sep=None, engine='python')\n",
    "            dataframes.append(df)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Error de codificación al leer el archivo {file}\")\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error de análisis al leer el archivo {file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error desconocido al leer el archivo {file}: {e}\")\n",
    "\n",
    "    if dataframes:\n",
    "        # Concatenar los DataFrames a lo largo de las columnas\n",
    "        merged_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "        # Guardar el DataFrame combinado en un nuevo archivo CSV\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Archivos CSV combinados exitosamente en {output_file}\")\n",
    "    else:\n",
    "        print(\"No se pudieron leer los archivos CSV.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cambiar los valores de la columna P404_RFINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\3180055563.py:10: DtypeWarning: Columns (22,31,50,75,83,109,115,121,127,133,139,145,151,157,164,171,175,181,199,235,244,318,351,355,368,371,430,454) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo DATA2.csv modificado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def modify_p404_rfinal():\n",
    "    # Archivo de entrada y salida\n",
    "    input_file = \"DATA1.csv\"\n",
    "    output_file = \"DATA2.csv\"  \n",
    "    \n",
    "    try:\n",
    "        # Leer el archivo DATA1.CSV con la codificación adecuada y manejo de tipos de datos mixtos si es necesario\n",
    "        df = pd.read_csv(input_file, encoding='utf-8')\n",
    "        \n",
    "        # Verificar si la columna P404_RFINAL existe antes de modificar sus valores\n",
    "        if 'P404_RFINAL' in df.columns:\n",
    "            # Modificar los valores según el diccionario de reemplazo\n",
    "            df['P404_RFINAL'] = df['P404_RFINAL'].replace({\n",
    "                1: 'Completa',\n",
    "                2: 'Incompleta',\n",
    "                3: 'Rechazo',\n",
    "                4: 'No se presento'\n",
    "            })\n",
    "        else:\n",
    "            print(\"La columna P404_RFINAL no existe en el archivo.\")\n",
    "\n",
    "        # Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8')  \n",
    "        \n",
    "        print(f\"Archivo {output_file} modificado exitosamente.\")\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error de codificación al leer el archivo {input_file}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error de análisis al leer el archivo {input_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error desconocido al leer el archivo {input_file}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modify_p404_rfinal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHORA FILTRAREMOS SOLO AQUELLAS ENCUESTAS QUE ESTEN COMPLETAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\1284371037.py:9: DtypeWarning: Columns (22,31,50,75,83,109,115,121,127,133,139,145,151,157,164,171,175,181,199,235,244,318,351,355,368,371,430,454) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo DATA3.csv generado exitosamente con filas completas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_complete_rows():\n",
    "    # Archivo de entrada y salida\n",
    "    input_file = \"DATA2.csv\"\n",
    "    output_file = \"DATA3.csv\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(input_file, encoding='utf-8')\n",
    "        \n",
    "        # Filtrar las filas donde P404_RFINAL es igual a 'Completa'\n",
    "        df_completa = df[df['P404_RFINAL'] == 'Completa']\n",
    "        \n",
    "        # Guardar el DataFrame filtrado en un nuevo archivo CSV\n",
    "        df_completa.to_csv(output_file, index=False, encoding='utf-8')  \n",
    "        \n",
    "        print(f\"Archivo {output_file} generado exitosamente con filas completas.\")\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error de codificación al leer el archivo {input_file}\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error de análisis al leer el archivo {input_file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error desconocido al leer el archivo {input_file}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_complete_rows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTAR LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\1900031580.py:13: DtypeWarning: Columns (31,50,54,75,83,87,96,103,109,115,121,127,133,139,145,151,157,159,164,166,171,175,178,181,187,199,218,220,224,232,235,244,253,261,270,279,293,299,301,303,305,307,310,315,318,321,323,334,347,351,355,368,369,371,374,376,389,406,414,416,418,420,423,430) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('DATA3.csv', encoding='utf-8', sep=',', on_bad_lines='skip')  # Lee el archivo CSV y omite las líneas con errores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataframe:\n",
      "   ID_CARATULA  INTERNO_ID  CUEST_NRO  CCDD         DD  CCPP         PP  CCDI  \\\n",
      "0          1.0         1.0        1.0    15       LIMA     1       LIMA     8   \n",
      "1          3.0         1.0        4.0     6  CAJAMARCA     1  CAJAMARCA     1   \n",
      "2          4.0         1.0        5.0    15       LIMA     1       LIMA    32   \n",
      "3          5.0         1.0        6.0    15       LIMA     1       LIMA    32   \n",
      "4          6.0         1.0        7.0    15       LIMA     1       LIMA    32   \n",
      "\n",
      "                       DI  CCCP  ... P403_4  P403_5 P403_5ESP  P403_6 P403_7  \\\n",
      "0              CHORRILLOS     1  ...    0.0     0.0       NaN     NaN    NaN   \n",
      "1               CAJAMARCA     1  ...    0.0     0.0       NaN     NaN    NaN   \n",
      "2  SAN JUAN DE LURIGANCHO     1  ...    0.0     0.0       NaN     1.0    NaN   \n",
      "3  SAN JUAN DE LURIGANCHO     1  ...    0.0     0.0       NaN     NaN    NaN   \n",
      "4  SAN JUAN DE LURIGANCHO     1  ...    0.0     0.0       NaN     NaN    NaN   \n",
      "\n",
      "      P404_FEC  P404_RFINAL P404_MNRPTA P404_MNRPTA_ESP  OMICAP400  \n",
      "0   19-04-2016     Completa         NaN             NaN        0.0  \n",
      "1   19-04-2016     Completa         NaN             NaN        0.0  \n",
      "2   06-04-2016     Completa         NaN             NaN        0.0  \n",
      "3   19-04-2016     Completa         NaN             NaN        0.0  \n",
      "4   19-04-2016     Completa         NaN             NaN        0.0  \n",
      "\n",
      "[5 rows x 456 columns]\n",
      "\n",
      "Información del dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75816 entries, 0 to 75815\n",
      "Columns: 456 entries, ID_CARATULA to OMICAP400\n",
      "dtypes: float64(354), int64(7), object(95)\n",
      "memory usage: 263.8+ MB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "        ID_CARATULA   INTERNO_ID     CUEST_NRO          CCDD          CCPP  \\\n",
      "count  75816.000000  75816.00000  75816.000000  75816.000000  75816.000000   \n",
      "mean   38320.457806  38853.00211   1557.523056     13.017279      2.698639   \n",
      "std    22027.155996  23784.26034  12074.478162      5.594041      3.711612   \n",
      "min        1.000000      1.00000      1.000000      1.000000      1.000000   \n",
      "25%    19260.750000  17490.75000      1.000000     10.000000      1.000000   \n",
      "50%    38264.500000  38350.00000      1.000000     15.000000      1.000000   \n",
      "75%    57397.250000  59352.25000      1.000000     15.000000      1.000000   \n",
      "max    76618.000000  97119.00000  97113.000000     25.000000     18.000000   \n",
      "\n",
      "               CCDI     CCCP  CCOF_REGIONAL  EST_PENIT_COD         PISO  ...  \\\n",
      "count  75816.000000  75816.0   75816.000000   75816.000000  75816.00000  ...   \n",
      "mean       9.000963      1.0     285.044054     292.278002      1.63170  ...   \n",
      "std       11.585481      0.0     188.017051     186.277101      0.75434  ...   \n",
      "min        1.000000      1.0     100.000000     101.000000      1.00000  ...   \n",
      "25%        1.000000      1.0     200.000000     203.000000      1.00000  ...   \n",
      "50%        4.000000      1.0     200.000000     216.000000      1.00000  ...   \n",
      "75%       11.000000      1.0     400.000000     401.000000      2.00000  ...   \n",
      "max       32.000000      1.0     800.000000     999.000000      5.00000  ...   \n",
      "\n",
      "             P403_1        P403_2        P403_3        P403_4        P403_5  \\\n",
      "count  75816.000000  75816.000000  75816.000000  75816.000000  75816.000000   \n",
      "mean       0.134338      0.928564      0.048934      0.013863      0.019178   \n",
      "std        0.341018      0.257554      0.215732      0.116921      0.137151   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "       P403_6  P403_7  P404_MNRPTA  P404_MNRPTA_ESP  OMICAP400  \n",
      "count  3691.0   762.0          0.0              0.0    75816.0  \n",
      "mean      1.0     1.0          NaN              NaN        0.0  \n",
      "std       0.0     0.0          NaN              NaN        0.0  \n",
      "min       1.0     1.0          NaN              NaN        0.0  \n",
      "25%       1.0     1.0          NaN              NaN        0.0  \n",
      "50%       1.0     1.0          NaN              NaN        0.0  \n",
      "75%       1.0     1.0          NaN              NaN        0.0  \n",
      "max       1.0     1.0          NaN              NaN        0.0  \n",
      "\n",
      "[8 rows x 361 columns]\n",
      "\n",
      "Valores nulos por columna antes de la limpieza:\n",
      "ID_CARATULA            0\n",
      "INTERNO_ID             0\n",
      "CUEST_NRO              0\n",
      "CCDD                   0\n",
      "DD                     0\n",
      "                   ...  \n",
      "P404_FEC               0\n",
      "P404_RFINAL            0\n",
      "P404_MNRPTA        75816\n",
      "P404_MNRPTA_ESP    75816\n",
      "OMICAP400              0\n",
      "Length: 456, dtype: int64\n",
      "\n",
      "Valores nulos por columna después de la limpieza:\n",
      "ID_CARATULA            0\n",
      "INTERNO_ID             0\n",
      "CUEST_NRO              0\n",
      "CCDD                   0\n",
      "DD                     0\n",
      "                   ...  \n",
      "P404_FEC               0\n",
      "P404_RFINAL            0\n",
      "P404_MNRPTA        75816\n",
      "P404_MNRPTA_ESP    75816\n",
      "OMICAP400              0\n",
      "Length: 456, dtype: int64\n",
      "\n",
      "Número de filas duplicadas antes de la limpieza:\n",
      "0\n",
      "\n",
      "Número de filas duplicadas después de la limpieza:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Importa la librería pandas para manipulación y análisis de datos estructurados\n",
    "\n",
    "import numpy as np  # Importa la librería NumPy para operaciones numéricas avanzadas y manejo eficiente de arreglos\n",
    "\n",
    "import matplotlib as plt  # Importa la biblioteca Matplotlib, que se utiliza para crear gráficos en Python\n",
    "import matplotlib.pyplot as plt  # Importa el módulo pyplot de Matplotlib, que proporciona una interfaz de estilo similar a MATLAB para la creación de gráficos\n",
    "\n",
    "import pandas as pd  # Importa la librería pandas para manipulación y análisis de datos estructurados\n",
    "import warnings  # Importa la librería warnings para controlar y manejar advertencias\n",
    "\n",
    "try:\n",
    "    # Intentar leer el archivo CSV con la codificación latin1 y manejo de errores de línea\n",
    "    df = pd.read_csv('DATA3.csv', encoding='utf-8', sep=',', on_bad_lines='skip')  # Lee el archivo CSV y omite las líneas con errores\n",
    "except Exception as e:\n",
    "    # Capturar cualquier excepción que ocurra al leer el archivo CSV\n",
    "    print(f\"Error al leer el archivo CSV: {e}\")  # Imprime un mensaje de error\n",
    "    df = None  # Asigna None al DataFrame si ocurre un error\n",
    "\n",
    "if df is not None:\n",
    "    try:\n",
    "        # Exploración inicial del conjunto de datos\n",
    "        print(\"Primeras filas del dataframe:\")  # Imprime un mensaje\n",
    "        print(df.head())  # Muestra las primeras filas del DataFrame\n",
    "\n",
    "        print(\"\\nInformación del dataframe:\")  # Imprime un mensaje\n",
    "        print(df.info())  # Muestra información general del DataFrame\n",
    "\n",
    "        print(\"\\nEstadísticas descriptivas:\")  # Imprime un mensaje\n",
    "        print(df.describe())  # Muestra estadísticas descriptivas de las columnas numéricas\n",
    "\n",
    "        # Manejar valores nulos\n",
    "        print(\"\\nValores nulos por columna antes de la limpieza:\")  # Imprime un mensaje\n",
    "        print(df.isnull().sum())  # Muestra la cantidad de valores nulos por columna\n",
    "\n",
    "        # Rellenar valores nulos con la media para columnas numéricas\n",
    "        num_cols = df.select_dtypes(include=['number']).columns  # Selecciona las columnas numéricas\n",
    "        df[num_cols] = df[num_cols].fillna(df[num_cols].mean())  # Rellena los valores nulos en las columnas numéricas con la media de la columna\n",
    "\n",
    "        print(\"\\nValores nulos por columna después de la limpieza:\")  # Imprime un mensaje\n",
    "        print(df.isnull().sum())  # Muestra la cantidad de valores nulos por columna después de la limpieza\n",
    "\n",
    "        # Manejar datos duplicados\n",
    "        print(\"\\nNúmero de filas duplicadas antes de la limpieza:\")  # Imprime un mensaje\n",
    "        print(df.duplicated().sum())  # Muestra la cantidad de filas duplicadas\n",
    "\n",
    "        df.drop_duplicates(inplace=True)  # Elimina las filas duplicadas del DataFrame\n",
    "\n",
    "        print(\"\\nNúmero de filas duplicadas después de la limpieza:\")  # Imprime un mensaje\n",
    "        print(df.duplicated().sum())  # Muestra la cantidad de filas duplicadas después de la limpieza\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Capturar cualquier excepción que ocurra al procesar el dataframe\n",
    "        print(f\"Error al procesar el dataframe: {e}\")  # Imprime un mensaje de error\n",
    "else:\n",
    "    print(\"No se pudo cargar el dataframe debido a errores previos.\")  # Imprime un mensaje si no se pudo cargar el DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REEMPLAZAR VALORES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\626383987.py:7: DtypeWarning: Columns (31,50,54,75,83,87,96,103,109,115,121,127,133,139,145,151,157,159,164,166,171,175,178,181,187,199,218,220,224,232,235,244,253,261,270,279,293,299,301,303,305,307,310,315,318,321,323,334,347,351,355,368,369,371,374,376,389,406,414,416,418,420,423,430) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('DATA3.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos limpiados y guardados en 'DATA4.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('DATA3.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n",
    "except Exception as e:\n",
    "    # Capturar cualquier excepción que ocurra al leer el archivo CSV\n",
    "    print(f\"Error al leer el archivo CSV: {e}\")\n",
    "    df = None\n",
    "mappings = {\n",
    "    'GENERO': {1: 'Hombre', 2: 'Mujer'},\n",
    "    'E_CIVIL': {\n",
    "        1: 'Conviviente', 2: 'Casado(a)', 3: 'Viudo(a)', 4: 'Divorciado(a)', \n",
    "        5: 'Separado(a)', 6: 'Soltero(a)'\n",
    "    },\n",
    "    'RELIGION': {\n",
    "        1: 'Catolica', 2: 'Evangelica', 3: 'Mormon', 4: 'Adventista', \n",
    "        5: 'Testigo de Jehova', 6: 'Otra', 7: 'Ninguna'\n",
    "    },\n",
    "    'SITUACION_JURIDICA': {1: 'Procesado', 2: 'Sentenciado'},\n",
    "    'P101': {\n",
    "        1: 'Quechua', 2: 'Aymara', 3: 'Ashaninka', 4: 'Awajun/Aguruna', \n",
    "        5: 'Shipibo/Konibo', 6: 'Otra lengua nativo', 7: 'Castellano', \n",
    "        8: 'Ingles', 9: 'Otra lengua extranjera', 10: 'Es sordomudo/a o mudo/a'\n",
    "    },\n",
    "    'P102': {1: 'Si', 2: 'No'},\n",
    "    'P103_1': {1: 'Si', 2: 'No'},\n",
    "    'P103_2': {1: 'Si', 2: 'No'},\n",
    "    'P103_3': {1: 'Si', 2: 'No'},\n",
    "    'P104_1': {\n",
    "        1: 'Sin nivel', 2: 'Educacion Inicial', 3: 'Primaria Incompleta', \n",
    "        4: 'Primaria Completa', 5: 'Secundaria Incompleta', 6: 'Secundaria Completa', \n",
    "        7: 'Superior no universitaria incompleta', 8: 'Superior no universitaria completa', \n",
    "        9: 'Superior universitaria incompleta', 10: 'Superior universitaria completa', \n",
    "        11: 'Postgrado'\n",
    "    },\n",
    "    'P104_4_CCEE': {1: 'Estatal', 2: 'No Estatal', 3: 'Omision'},\n",
    "    'P105': {\n",
    "        1: 'La familia no le permitió', 2: 'La familia es/era muy pobre', \n",
    "        3: 'Tenía necesidad económica', 4: 'No le gustaba estudiar', \n",
    "        5: 'Lo expulsaron', 6: 'Por haber ingresado a prisión', \n",
    "        7: 'Tenía que cuidar a mis hermanos(as)', 8: 'Mi pareja me lo impidió', \n",
    "        9: 'Otra', 10: 'No sabe / No contesta', 11: 'Problemas de Salud', \n",
    "        12: 'Problemas familiares'\n",
    "    },\n",
    "    'P106': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P109_1': {1: 'Si', 2: 'No', 3: 'No contesta'},\n",
    "    'P109A_1': {\n",
    "        1: 'Marihuana', 2: 'Inhalantes', 3: 'Pasta básica / Cocaína o crack', \n",
    "        4: 'Pastillas', 5: 'Otro tipo de droga', 6: 'Cerveza', 7: 'Chicha', \n",
    "        8: 'Otro tipo de licor', 9: 'Ron', 10: 'Whisky', 11: 'Aguardiente'\n",
    "    },\n",
    "    'P109C_1': {1: 'Si', 2: 'No'},\n",
    "    'P109D_1': {\n",
    "        1: 'Diario', 2: '2 a 6 veces a la semana', 3: 'Semanal', 4: 'Quincenal', \n",
    "        5: 'Mensual', 6: 'Otra frecuencia'\n",
    "    },\n",
    "    'P109_2': {1: 'Si', 2: 'No', 3: 'No contesta'},\n",
    "    'P109A_2': {\n",
    "        1: 'Marihuana', 2: 'Inhalantes', 3: 'Pasta básica / Cocaína o crack', \n",
    "        4: 'Pastillas', 5: 'Otro tipo de droga', 6: 'Cerveza', 7: 'Chicha', \n",
    "        8: 'Otro tipo de licor', 9: 'Ron', 10: 'Whisky', 11: 'Aguardiente'\n",
    "    },\n",
    "    'P109C_2': {1: 'Si', 2: 'No'},\n",
    "    'P109D_2': {\n",
    "        1: 'Diario', 2: '2 a 6 veces a la semana', 3: 'Semanal', 4: 'Quincenal', \n",
    "        5: 'Mensual', 6: 'Otra frecuencia'\n",
    "    },\n",
    "    'P109_3': {1: 'Si', 2: 'No', 3: 'No contesta'},\n",
    "    'P109C_3': {1: 'Si', 2: 'No'},\n",
    "    'P109D_3': {\n",
    "        1: 'Diario', 2: '2 a 6 veces a la semana', 3: 'Semanal', 4: 'Quincenal', \n",
    "        5: 'Mensual', 6: 'Otra frecuencia'\n",
    "    },\n",
    "    'P110': {1: 'Si', 2: 'No'},\n",
    "    'P110A': {1: 'Si', 2: 'No'},\n",
    "    'P110B': {1: 'Si', 2: 'No'},\n",
    "    'P110C': {\n",
    "        1: 'No tiene dinero', 2: 'No confía en los médicos', 3: 'No es necesario', \n",
    "        4: 'No tiene seguro de salud', 5: 'Por el maltrato del personal de salud', \n",
    "        6: 'No me han confirmado el embarazo', 7: 'Otro'\n",
    "    },\n",
    "    'P111': {1: 'Si', 2: 'No'},\n",
    "    'P112': {\n",
    "        1: 'Heterosexual', 2: 'Bisexual', \n",
    "        3: 'Homosexual (lesbiana, gay, transexual, intersexual)', \n",
    "        4: 'No responde'\n",
    "    },\n",
    "    'P113_1': {1: 'Si', 2: 'No'},\n",
    "    'P113_2': {1: 'Si', 2: 'No'},\n",
    "    'P113_3': {1: 'Si', 2: 'No'},\n",
    "    'P113_4': {1: 'Si', 2: 'No'},\n",
    "    'P113_5': {1: 'Si', 2: 'No'},\n",
    "    'P113_6': {1: 'Si', 2: 'No'},\n",
    "    'P113A_1': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P113A_2': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P113A_3': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P113A_4': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P113A_5': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P113A_6': {1: 'Leve', 2: 'Moderada', 3: 'Severa'},\n",
    "    'P114': {1: 'Si', 2: 'No'},\n",
    "    'P117': {\n",
    "        1: 'Empleador o patrono', 2: 'Trabajador dependiente', 3: 'Empleado', \n",
    "        4: 'Obrero', 5: 'Trabajador familiar no remunerado', 6: 'Trabajador del hogar', \n",
    "        7: 'Otro'\n",
    "    },\n",
    "    'P118': {\n",
    "        1: 'Falta de estudios', 2: 'Problemas de salud', \n",
    "        3: 'Por tener antecedentes penales/Judiciales', \n",
    "        4: 'Responsabilidades familiares', 5: 'Estaba estudiando', \n",
    "        6: 'No necesitaba trabajar', 7: 'No quería trabajar', \n",
    "        8: 'Tenía un “trabajo” ilegal', 9: 'Era alcohólico o drogadicto', \n",
    "        10: 'Era jubilado', 11: 'No encontraba trabajo', \n",
    "        12: 'Dedicado a los quehaceres del hogar', 13: 'Otro', 14: 'No contesta'\n",
    "    },\n",
    "    'P119_1': {1: 'Si', 2: 'No'},\n",
    "    'P119_2': {1: 'Si', 2: 'No'},\n",
    "    'P119_3': {1: 'Si', 2: 'No'},\n",
    "    'P119_4': {1: 'Si', 2: 'No'},\n",
    "    'P119_5': {1: 'Si', 2: 'No'},\n",
    "    'P119_6': {1: 'Si', 2: 'No'},\n",
    "    'P120': {\n",
    "        1: 'Quechua?', 2: 'Aymara?', 3: 'Nativo o indígena de la Amazonía?', \n",
    "        4: 'Parte de otro pueblo originario?', 5: 'Negro/Moreno/Zambo/Afroperuano?', \n",
    "        6: 'Blanco?', 7: 'Mestizo?', 8: 'Otro?', 9: 'No sabe / No responde'\n",
    "    },\n",
    "    'P121': {1: 'Si', 2: 'No', 3: 'No sabe'},\n",
    "    'P122_NO': {1: 'No recuerda'},\n",
    "    'P123_1': {1: 'Si', 2: 'No'},\n",
    "    'P123_2': {1: 'Si', 2: 'No'},\n",
    "    'P123_3': {1: 'Si', 2: 'No'},\n",
    "    'P123_4': {1: 'Si', 2: 'No'},\n",
    "    'P123_5': {1: 'Si', 2: 'No'},\n",
    "    'P123_6': {1: 'Si', 2: 'No'},\n",
    "    'P124_NO': {1: 'Nunca vivio con su papá'},\n",
    "    'P125_1': {1: 'Si', 2: 'No'},\n",
    "    'P125_2': {1: 'Si', 2: 'No'},\n",
    "    'P125_3': {1: 'Si', 2: 'No'},\n",
    "    'P125_4': {1: 'Si', 2: 'No'},\n",
    "    'P125_5': {1: 'Si', 2: 'No'},\n",
    "    'P125_6': {1: 'Si', 2: 'No'},\n",
    "    'P126': {1: 'Si, siempre', 2: 'Si, a veces', 3: 'No', 4: 'No contesta'},\n",
    "    'P127': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P128': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P129': {1: 'Si', 2: 'No', 3: 'No aplica', 4: 'No sabe / No contesta'},\n",
    "    'P130': {1: 'Si', 2: 'No', 3: 'No recuerda / No contesta'},\n",
    "    'P131': {\n",
    "        1: 'Menos de 7 años', 2: 'Entre 7 y 12 años', 3: 'Más de 12 años', \n",
    "        4: 'No recuerda / No contesta'\n",
    "    },\n",
    "    'P132': {\n",
    "        1: 'Para buscar trabajo', 2: 'Por el abandono o separación de los padres', \n",
    "        3: 'Lo botaron de la casa', 4: 'Muerte de (los) padre(s)', \n",
    "        5: 'Alcoholismo o drogadicción del (los) padre(s)', 6: 'Violencia en la familia', \n",
    "        7: 'Abuso sexual', 8: 'Violación sexual', 9: 'Otro', 10: 'Por independizarse', \n",
    "        11: 'Mala influencia', 12: 'Por rebeldía', 13: 'Por problemas familiares', \n",
    "        14: 'Para estudiar'\n",
    "    },\n",
    "    'P133': {1: 'Si', 2: 'No', 3: 'No recuerda / No contesta'},\n",
    "    'P135': {1: 'Si', 2: 'No', 3: 'No recuerda / No contesta'},\n",
    "    'P136': {1: 'Si', 2: 'No', 3: 'No recuerda / No contesta'},\n",
    "    'P137': {1: 'Si', 2: 'No'},\n",
    "    'P138': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P139': {1: 'Si', 2: 'No'},\n",
    "    'P140': {\n",
    "        1: 'Por su color de piel/raza', 2: 'Por su idioma/lengua/forma de hablar/dejo/acento', \n",
    "        3: 'Por sus costumbres (música, comida, vestimenta)', \n",
    "        4: 'Por su origen familiar/su lugar de nacimiento/su región de procedencia', \n",
    "        5: 'Por ser pobre/no tener dinero', 6: 'Por su lugar de residencia/donde vive', \n",
    "        7: 'Por no tener conocidos o vara', 8: 'Por tener alguna discapacidad', \n",
    "        9: 'Por ser mujer', 10: 'Por su orientación sexual', \n",
    "        11: 'Por antecedentes penales / judiciales', 12: 'Por tatuajes cicatrices', \n",
    "        13: 'Otro'\n",
    "    },\n",
    "    'P141_1': {0: 'No', 1: 'Si'},\n",
    "    'P141_2': {0: 'No', 1: 'Si'},\n",
    "    'P141_3': {0: 'No', 1: 'Si'},\n",
    "    'P141_4': {0: 'No', 1: 'Si'},\n",
    "    'P141_5': {0: 'No', 1: 'Si'},\n",
    "    'P141_6': {0: 'No', 1: 'Si'},\n",
    "    'P141_7': {0: 'No', 1: 'Si'},\n",
    "    'P141_8': {0: 'No', 1: 'Si'},\n",
    "    'P141_9': {0: 'No', 1: 'Si'},\n",
    "    'P141_10': {0: 'No', 1: 'Si'},\n",
    "    'P141_11': {0: 'No', 1: 'Si'},\n",
    "    'P141_12': {0: 'No', 1: 'Si'},\n",
    "    'P141_13': {0: 'No', 1: 'Si'},\n",
    "    'P202': {\n",
    "        1: 'Vía pública', 2: 'Vivienda de la víctima', 3: 'Local comercial bancario o esparcimiento', \n",
    "        4: 'Centro de trabajo', 5: 'Vehículo público', 6: 'Vehículo privado', \n",
    "        7: 'Campo abierto / lugar desolado', 8: 'Casa o establecimiento abandonado', \n",
    "        9: 'Dependencia policial / cuartel', 10: 'En el mar, acantilado, acequia, canal', \n",
    "        11: 'Hogar del interno', 12: 'Puerto / Aeropuerto', 13: 'Otros', \n",
    "        14: 'No contesta', 15: 'No sabe', 16: 'Casa de familiar'\n",
    "    },\n",
    "    'P203': {\n",
    "        1: 'Por venganza', 2: 'Por ajuste de cuentas', 3: 'Por celos', \n",
    "        4: 'Por mala práctica profesional', 5: 'Por lucro personal', \n",
    "        6: 'Por emoción violenta', 7: 'Otro', 8: 'No sabe', 9: 'Placer sexual', \n",
    "        10: 'Por involucrarse', 11: 'Bajo el efecto de drogas y/o bebidas alcoholicas', \n",
    "        12: 'Trafico de drogas'\n",
    "    },\n",
    "    'P204': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P205': {1: 'De fuego', 2: 'Punzo cortante', 3: 'Otros', 4: 'No sabe / No contesta'},\n",
    "    'P206': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P207_NO': {1: 'No sabe / No contesta'},\n",
    "    'P208': {\n",
    "        1: 'No sabe / No contesta', 2: 'La compró', 3: 'La robó', 4: 'Se la dio un amigo/os', \n",
    "        5: 'Se la dio un familiar', 6: 'Siendo policía o militar', 7: 'Otro', \n",
    "        8: 'No sabe / No contesta'\n",
    "    },\n",
    "    'P209': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P210': {\n",
    "        1: 'Alcohol', 2: 'Marihuana', 3: 'Inhalantes (terocal u otros)', \n",
    "        4: 'Pasta básica / cocaína / crack', 5: 'Pastillas', 6: 'Heroína', \n",
    "        7: 'Otro', 8: 'No sabe / No contesta'\n",
    "    },\n",
    "    'P211': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P212': {\n",
    "        1: 'Era(n) familiar(es)', 2: 'Era(n) amigo(s)', 3: 'Era(n) conocido(s) de donde vivía', \n",
    "        4: 'Era(n) alguien de donde estudiaba', 5: 'Era(n) alguien del trabajo', \n",
    "        6: 'Era(n) alguien que acababa de conocer', 7: 'Otro', 8: 'No sabe / No contesta'\n",
    "    },\n",
    "    'P213': {\n",
    "        1: 'Conseguir dinero para comprarme lo que quería', 2: 'Traer dinero a la casa', \n",
    "        3: 'Porque me daba reputación entre mis conocidos', \n",
    "        4: 'Por la emoción del riesgo de hacerlo', 5: 'Porque me obligaron mis familiares', \n",
    "        6: 'Porque mis amigos lo hacían', 7: 'Porque estaba aburrido', \n",
    "        8: 'Porque no tenía miedo a la policía', 9: 'Otro', 10: 'No sabe / No contesta', \n",
    "        11: 'No cometio delito a esa edad', 12: 'No participo del hecho'\n",
    "    },\n",
    "    'P214': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P215': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P216': {1: 'Procesado', 2: 'Sentenciado'},\n",
    "    'P217': {1: 'Si', 2: 'No'},\n",
    "    'P217A': {1: 'Defensor Público (Abogado de oficio)', 2: 'Abogado particular'},\n",
    "    'P218': {1: 'Inocente', 2: 'Culpable'},\n",
    "    'P219': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P220': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P301': {1: 'Nada limpios', 2: 'Poco limpios', 3: 'Limpios', 4: 'Muy limpios', 5: 'No sabe / No contesta'},\n",
    "    'P302': {1: 'Muy mala', 2: 'Mala', 3: 'Buena', 4: 'Muy buena', 5: 'No sabe / No contesta'},\n",
    "    'P303': {1: 'Si', 2: 'No'},\n",
    "    'P309': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P310': {1: 'Si', 2: 'No'},\n",
    "    'P311_1': {1: 'No tuvo Dinero'},\n",
    "    'P311_2': {1: 'Demoran mucho en atender'},\n",
    "    'P311_3': {1: 'No confia en los medicos'},\n",
    "    'P311_4': {1: 'No era grave/ No fue necesario'},\n",
    "    'P311_5': {1: 'Prefiere curarse con remedios caseros'},\n",
    "    'P311_6': {1: 'No tiene seguro'},\n",
    "    'P311_7': {1: 'Se auto receto'},\n",
    "    'P311_8': {1: 'Falta de Tiempo'},\n",
    "    'P311_9': {1: 'Por el Maltrato del personal de salud'},\n",
    "    'P311_10': {1: 'No correspondia atencion para su pabellos'},\n",
    "    'P311_11': {1: 'otro'},\n",
    "    'P313_1': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P313_2': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P313_3': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P313_4': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P313_5': {1: 'Si', 2: 'No', 3: 'No sabe / No contesta'},\n",
    "    'P314': {\n",
    "        1: 'Porque no le proporcionan ningún trabajo', \n",
    "        2: 'Porque no le gustan los trabajos que le ofrecen', 3: 'Porque estudia', \n",
    "        4: 'Porque no tengo el dinero para pagar el taller', 5: 'Porque no es rentable', \n",
    "        6: 'Porque no tienen material y/o herramienta para trabajar', 7: 'Otros', \n",
    "        8: 'No sabe / No contesta', 9: 'Ingreso recien al penal', 10: 'Por enfermedad y/o estado de salud'\n",
    "    },\n",
    "    'P315': {\n",
    "        1: 'Tres veces por semana', 2: 'Dos veces por semana', 3: 'Una vez por semana', \n",
    "        4: 'Cada 15 días', 5: 'Una vez al mes', 6: 'Cada tres meses', \n",
    "        7: 'Una vez al año', 8: 'Nunca', 9: 'Otros', 10: 'No sabe / No contesta'\n",
    "    },\n",
    "    'P316': {\n",
    "        1: 'Papá/padrastro', 2: 'Mamá/madrasta', 3: 'Hijos(as)', 4: 'Pareja', \n",
    "        5: 'Hermanos(as)', 6: 'Abuelo(a)', 7: 'TÍos(as)', 8: 'Amigos(as)', \n",
    "        9: 'Otros', 10: 'Ambos padres'\n",
    "    },\n",
    "    'P317': {1: 'Si', 2: 'No'},\n",
    "    'P318': {\n",
    "        1: 'Por su color de piel/raza', 2: 'Por su idioma/ lengua/ forma de hablar/dejo/ acento', \n",
    "        3: 'Por sus costumbres (música, comida y vestimenta)', \n",
    "        4: 'Por su origen familiar/ su lugar de Nacimiento/ su región de procedencia', \n",
    "        5: 'Por tener alguna discapacidad', 6: 'Por ser mujer', 7: 'Por su orientación sexual', \n",
    "        8: 'Otra', 9: 'Por el delito cometido', 10: 'Por estar preso'\n",
    "    },\n",
    "    'P319_1': {1: 'Personal de la PNP'},\n",
    "    'P319_2': {1: 'Personal de seguridad'},\n",
    "    'P319_3': {1: 'Personal del INPE'},\n",
    "    'P319_4': {1: 'Abogados'},\n",
    "    'P319_5': {1: 'Compañeros del EP'},\n",
    "    'P319_6': {1: 'Otros'},\n",
    "    'P319_7': {1: 'No sabe / No contesta'},\n",
    "    'P401_1': {1: 'Realizar una llamada telefonica'},\n",
    "    'P401_2': {1: 'Recibir la asistencia de un abogado'},\n",
    "    'P401_3': {1: 'No declarar'},\n",
    "    'P401_4': {1: 'No recuerda / No contesta'},\n",
    "    'P402_NO': {1: 'No recuerda / No contesta'},\n",
    "    'P403_1': {1: 'Estudiar'},\n",
    "    'P403_2': {1: 'Trabajar'},\n",
    "    'P403_3': {1: 'Viajar'},\n",
    "    'P403_4': {1: 'Retornar a mi pais'},\n",
    "    'P403_5': {1: 'Otros'},\n",
    "    'P403_6': {1: 'Regresar con mi familia'},\n",
    "    'P403_7': {1: 'Reincorporarme con la sociedad'}\n",
    "}\n",
    "\n",
    "# Apply mappings to respective columns\n",
    "for col, mapping in mappings.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping)\n",
    "        \n",
    "        \n",
    "if 'df' in locals():\n",
    "    # Guardar el conjunto de datos limpio\n",
    "    df.to_csv('DATA4.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nDatos limpiados y guardados en 'DATA4.csv'\")\n",
    "else:\n",
    "    print(\"No se pudo cargar el archivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar lo innecesario \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eliminar lo de caratula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\4086605572.py:7: DtypeWarning: Columns (31,50,54,74,75,76,83,87,88,89,90,91,94,95,96,97,103,109,115,121,127,133,139,145,151,157,159,164,166,171,175,178,179,180,181,183,184,185,186,187,189,190,191,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,218,220,221,223,224,225,226,227,228,229,230,231,232,233,235,237,238,239,240,241,242,243,244,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,270,271,272,273,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,299,301,303,304,305,306,307,308,309,310,311,313,314,315,316,317,318,319,320,321,322,323,324,333,334,335,336,337,338,339,342,347,351,355,361,362,363,368,369,371,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,406,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,446,450) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('DATA4.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datos limpiados y guardados en 'DATA5.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('DATA4.csv', encoding='utf-8', sep=',', on_bad_lines='skip')\n",
    "except Exception as e:\n",
    "    # Capturar cualquier excepción que ocurra al leer el archivo CSV\n",
    "    print(f\"Error al leer el archivo CSV: {e}\")\n",
    "    df = None\n",
    "    \n",
    "\n",
    "# Filtrar y eliminar datos innecesarios\n",
    "columnas_a_eliminar = ['ID_CARATULA','INTERNO_ID','CCDD','CCPP', 'CCDI','CCCP','CCOF_REGIONAL','EST_PENIT_COD','PABELLON','PISO',\n",
    "                        'ALA','AMBIENTE','RELIGION_ESP','PAIS_NAC_COD','NAC_CCDD','NAC_CCPP','NAC_CCDI','NAC_CCCP','INT_CCDD',\n",
    "                        'INT_CCPP','INT_CCDI','INT_CCCP','TSALUD_1','TSALUD_2','TSALUD_3','TSALUD_4','TSALUD_5','TSALUD_6',\n",
    "                        'TSALUD_7','TSALUD_8','TSALUD_7ESP','INT_TIPOVIA','INT_NOMBVIA','INT_PUERTA','INT_BLOCK','INT_INTERIOR',\n",
    "                        'INT_PISO','INT_MZ','INT_LOTE','INT_KILOMETRO','INT_REFERENCIA','DEL_GENERICO_CD','DEL_ESPECIFICO_CD',\n",
    "                        'OTROS_DELITOS',\n",
    "                        'ID_CARATULA.1', 'INTERNO_ID.1', 'CUEST_NRO.1', 'P101_ESP', 'P102A_1', 'P102A_2', 'P102A_3', 'P102A_4', 'P102A_5', \n",
    "                        'P102A_6', 'P102A_6ESP', 'P102A_7', 'P102A_8', 'P102A_9', 'P102A_9ESP', 'P104_2_ANIO', 'P104_3_GRADO', 'P105_ESP', \n",
    "                        'P107_1', 'P107A_1', 'P107B_1', 'P107C_1', 'P107D_1', 'P107D_1ESP', 'P107_2', 'P107A_2', 'P107B_2', 'P107C_2', \n",
    "                        'P107D_2', 'P107D_2ESP', 'P107_3', 'P107A_3', 'P107B_3', 'P107C_3', 'P107D_3', 'P107D_3ESP', 'P107_4', 'P107A_4', \n",
    "                        'P107B_4', 'P107C_4', 'P107D_4', 'P107D_4ESP', 'P107_5', 'P107A_5', 'P107B_5', 'P107C_5', 'P107D_5', 'P107D_5ESP', \n",
    "                        'P107_6', 'P107A_6', 'P107B_6', 'P107C_6', 'P107D_6', 'P107D_6ESP', 'P107_7', 'P107A_7', 'P107B_7', 'P107C_7', \n",
    "                        'P107D_7', 'P107D_7ESP', 'P107_8', 'P107A_8', 'P107B_8', 'P107C_8', 'P107D_8', 'P107D_8ESP', 'P107_9', 'P107A_9', \n",
    "                        'P107B_9', 'P107C_9', 'P107D_9', 'P107D_9ESP', 'P107_10', 'P107A_10', 'P107B_10', 'P107C_10', 'P107D_10', \n",
    "                        'P107D_10ESP', 'P107_11', 'P107_11ESP', 'P107A_11', 'P107B_11', 'P107C_11', 'P107D_11', 'P107D_11ESP', 'P107_12', \n",
    "                        'P107_12ESP', 'P1079A_12', 'P107B_12', 'P107C_12', 'P107D_12', 'P107D_12ESP', 'P108_1', 'P108_2', 'P108_3', \n",
    "                        'P108_3ESP', 'P108_4', 'P108_5', 'P108_5ESP', 'P109A_1ESP', 'P109A_2ESP', 'P110C_ESP', 'P115_COD', 'P116_COD', \n",
    "                        'P116', 'P117_ESP', 'P118_ESP', 'P120_ESP', 'P121A', 'P121A_ESP', 'P123_6ESP', 'P125_6ESP', 'P132_ESP', 'P134_1', \n",
    "                        'P134_2', 'P134_3', 'P134_4', 'P134_5', 'P134_6', 'P134_7', 'P134_7ESP', 'P140_ESP', 'P141_13ESP', 'OMICAP100','ID_CARATULA.2', 'INTERNO_ID.2', 'CUEST_NRO.2', 'P201_CCDD', 'P201_CCPP', 'P201_CCDI', 'P202_ESP', 'P203_ESP', \n",
    "                        'P205_ESP', 'P208_ESP', 'P210_ESP', 'P212_ESP', 'P213_ESP', 'P214A_1', 'P214A_2', 'P214A_3', 'P214A_4', 'P214A_5', \n",
    "                        'P214A_6', 'P214A_7', 'P214A_6ESP', 'P215A', 'P220A', 'P220A_NO', 'P221_1', 'P222_1', 'P222_1ESP', 'P223_1', \n",
    "                        'P221_2', 'P222_2', 'P222_2ESP', 'P223_2', 'P221_3', 'P222_3', 'P222_3ESP', 'P223_3', 'OMICAP200',\n",
    "                        'ID_CARATULA.3', 'INTERNO_ID.3', 'CUEST_NRO.3', 'P304_1_A', 'P304_2_A', 'P304_3_A', 'P304_4_A', 'P304_4_IES', 'P305', \n",
    "                        'P306', 'P306_ESP', 'P307', 'P308', 'P308_ESP', 'P309A', 'P311_11ESP', 'P312_1', 'P312A_1', 'P312B_1', 'P312_2', \n",
    "                        'P312A_2', 'P312B_2', 'P312_3', 'P312A_3', 'P312B_3', 'P312_4', 'P312A_4', 'P312B_4', 'P312_5', 'P312A_5', 'P312B_5', \n",
    "                        'P312_6', 'P312_6ESP', 'P312A_6', 'P312B_6', 'P313_5ESP', 'P314_ESP', 'P315_ESP', 'P316_ESP', 'P318_ESP', \n",
    "                        'P319_6ESP', 'OMICAP300', 'ID_CARATULA.4', 'INTERNO_ID.4', 'CUEST_NRO.4', 'P404_FEC', 'P404_RFINAL', 'P404_MNRPTA', \n",
    "                        'P404_MNRPTA_ESP', 'OMICAP400','P403_5ESP'              ]\n",
    "df.drop(columnas_a_eliminar, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Guardar el conjunto de datos limpio\n",
    "    df.to_csv('DATA5.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nDatos limpiados y guardados en 'DATA5.csv'\")\n",
    "else:\n",
    "    print(\"No se pudo cargar el archivo CSV.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verificar el tipo de dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_12044\\2597287055.py:4: DtypeWarning: Columns (50,51,52,53,111,164) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('DATA5.csv', encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de todas las columnas:\n",
      "CUEST_NRO: float64\n",
      "DD: object\n",
      "PP: object\n",
      "DI: object\n",
      "CP: object\n",
      "OF_REGIONAL: object\n",
      "EST_PENIT: object\n",
      "GENERO: object\n",
      "E_CIVIL: object\n",
      "RELIGION: object\n",
      "EDAD: float64\n",
      "FEC_NAC_DIA: float64\n",
      "FEC_NAC_MES: float64\n",
      "FEC_NAC_ANIO: float64\n",
      "NACIONALIDAD: object\n",
      "PAIS_NAC: object\n",
      "NAC_DD: object\n",
      "NAC_PP: object\n",
      "NAC_DI: object\n",
      "NAC_CP: object\n",
      "INT_DD: object\n",
      "INT_PP: object\n",
      "INT_DI: object\n",
      "INT_CP: object\n",
      "SITUACION_JURIDICA: object\n",
      "DELITO_GENERICO: object\n",
      "DELITO_ESPECIFICO: object\n",
      "P101: object\n",
      "P102: object\n",
      "P103_1: object\n",
      "P103_2: object\n",
      "P103_3: object\n",
      "P104_1: object\n",
      "P104_4_CCEE: object\n",
      "P105: object\n",
      "P106: object\n",
      "P109_1: object\n",
      "P109A_1: object\n",
      "P109B_1: float64\n",
      "P109C_1: object\n",
      "P109D_1: object\n",
      "P109_2: object\n",
      "P109A_2: object\n",
      "P109B_2: float64\n",
      "P109C_2: object\n",
      "P109D_2: object\n",
      "P109_3: object\n",
      "P109B_3: float64\n",
      "P109C_3: object\n",
      "P109D_3: object\n",
      "P110: object\n",
      "P110A: object\n",
      "P110B: object\n",
      "P110C: object\n",
      "P111: object\n",
      "P112: object\n",
      "P113_1: object\n",
      "P113_2: object\n",
      "P113_3: object\n",
      "P113_4: object\n",
      "P113_5: object\n",
      "P113_6: object\n",
      "P113A_1: object\n",
      "P113A_2: object\n",
      "P113A_3: object\n",
      "P113A_4: object\n",
      "P113A_5: object\n",
      "P113A_6: object\n",
      "P114: object\n",
      "P114A: float64\n",
      "P114A_NO: float64\n",
      "P115: object\n",
      "P117: object\n",
      "P118: object\n",
      "P119_1: object\n",
      "P119_2: object\n",
      "P119_3: object\n",
      "P119_4: object\n",
      "P119_5: object\n",
      "P119_6: object\n",
      "P120: object\n",
      "P121: object\n",
      "P122: float64\n",
      "P122_NO: object\n",
      "P123_1: object\n",
      "P123_2: object\n",
      "P123_3: object\n",
      "P123_4: object\n",
      "P123_5: object\n",
      "P123_6: object\n",
      "P124: float64\n",
      "P124_NO: object\n",
      "P125_1: object\n",
      "P125_2: object\n",
      "P125_3: object\n",
      "P125_4: object\n",
      "P125_5: object\n",
      "P125_6: object\n",
      "P126: object\n",
      "P127: object\n",
      "P128: object\n",
      "P129: object\n",
      "P130: object\n",
      "P131: object\n",
      "P132: object\n",
      "P133: object\n",
      "P135: object\n",
      "P136: object\n",
      "P137: object\n",
      "P137A_HIJO: float64\n",
      "P137A_HIJA: float64\n",
      "P138: object\n",
      "P139: object\n",
      "P140: object\n",
      "P141_1: object\n",
      "P141_2: object\n",
      "P141_3: object\n",
      "P141_4: object\n",
      "P141_5: object\n",
      "P141_6: object\n",
      "P141_7: object\n",
      "P141_8: object\n",
      "P141_9: object\n",
      "P141_10: object\n",
      "P141_11: object\n",
      "P141_12: object\n",
      "P141_13: object\n",
      "P201_DD: object\n",
      "P201_PP: object\n",
      "P201_DI: object\n",
      "P202: object\n",
      "P203: object\n",
      "P204: object\n",
      "P205: object\n",
      "P206: object\n",
      "P207: float64\n",
      "P207_NO: object\n",
      "P208: object\n",
      "P209: object\n",
      "P210: object\n",
      "P211: object\n",
      "P212: object\n",
      "P213: object\n",
      "P214: object\n",
      "P215: object\n",
      "P216: object\n",
      "P217: object\n",
      "P217A: object\n",
      "P218: object\n",
      "P219: object\n",
      "P219A: float64\n",
      "P219A_NO: float64\n",
      "P220: object\n",
      "P301: object\n",
      "P302: object\n",
      "P303: object\n",
      "P309: object\n",
      "P310: object\n",
      "P311_1: object\n",
      "P311_2: object\n",
      "P311_3: object\n",
      "P311_4: object\n",
      "P311_5: object\n",
      "P311_6: object\n",
      "P311_7: object\n",
      "P311_8: object\n",
      "P311_9: object\n",
      "P311_10: object\n",
      "P311_11: object\n",
      "P313_1: object\n",
      "P313_2: object\n",
      "P313_3: object\n",
      "P313_4: object\n",
      "P313_5: object\n",
      "P314: object\n",
      "P315: object\n",
      "P316: object\n",
      "P317: object\n",
      "P318: object\n",
      "P319_1: object\n",
      "P319_2: object\n",
      "P319_3: object\n",
      "P319_4: object\n",
      "P319_5: object\n",
      "P319_6: object\n",
      "P319_7: object\n",
      "P401_1: object\n",
      "P401_2: object\n",
      "P401_3: object\n",
      "P401_4: object\n",
      "P402_M: float64\n",
      "P402_A: float64\n",
      "P402_NO: object\n",
      "P403_1: object\n",
      "P403_2: object\n",
      "P403_3: object\n",
      "P403_4: object\n",
      "P403_5: object\n",
      "P403_6: object\n",
      "P403_7: object\n",
      "\n",
      "Datos limpiados y guardados en 'DATA6.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('DATA5.csv', encoding='utf-8')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: No se encontró el archivo 'DATA5.csv': {e}\")\n",
    "    data = None\n",
    "except Exception as e:\n",
    "    print(f\"Error al leer el archivo 'DATA5.csv': {e}\")\n",
    "    data = None\n",
    "\n",
    "if data is not None:\n",
    "    # Mostrar los tipos de datos de todas las columnas\n",
    "    print(\"Tipos de datos de todas las columnas:\")\n",
    "    for column, dtype in data.dtypes.items():\n",
    "        print(f\"{column}: {dtype}\")\n",
    "\n",
    "    # Convertir 'CUEST_NRO' a entero\n",
    "    data['CUEST_NRO'] = data['CUEST_NRO'].astype(int)\n",
    "\n",
    "    # Función para convertir valores a enteros, reemplazando valores no válidos con None\n",
    "    def to_int(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "\n",
    "    # Aplicar la función a la columna 'EDAD'\n",
    "    data['EDAD'] = data['EDAD'].apply(to_int)\n",
    "\n",
    "    # Convertir otras columnas que deben ser enteros\n",
    "    int_columns = ['FEC_NAC_DIA', 'FEC_NAC_MES', 'FEC_NAC_ANIO', 'P109B_1', 'P109B_2', 'P109B_3', 'P114A', 'P122', 'P124', 'P137A_HIJO', 'P137A_HIJA', 'P207', 'P219A', 'P402_M', 'P402_A']\n",
    "    for col in int_columns:\n",
    "        data[col] = data[col].apply(to_int)\n",
    "\n",
    "    # Convertir las columnas a sus tipos adecuados\n",
    "    data = data.astype({\n",
    "    'CUEST_NRO': 'int',\n",
    "    'DD': 'str',\n",
    "    'PP': 'str',\n",
    "    'DI': 'str',\n",
    "    'CP': 'str',\n",
    "    'OF_REGIONAL': 'str',\n",
    "    'EST_PENIT': 'str',\n",
    "    'GENERO': 'str',\n",
    "    'E_CIVIL': 'str',\n",
    "    'RELIGION': 'str',\n",
    "    'NACIONALIDAD': 'str',\n",
    "    'PAIS_NAC': 'str',\n",
    "    'NAC_DD': 'str',\n",
    "    'NAC_PP': 'str',\n",
    "    'NAC_DI': 'str',\n",
    "    'NAC_CP': 'str',\n",
    "    'INT_DD': 'str',\n",
    "    'INT_PP': 'str',\n",
    "    'INT_DI': 'str',\n",
    "    'INT_CP': 'str',\n",
    "    'SITUACION_JURIDICA': 'str',\n",
    "    'DELITO_GENERICO': 'str',\n",
    "    'DELITO_ESPECIFICO': 'str',\n",
    "    'P101': 'str',\n",
    "    'P102': 'str',\n",
    "    'P103_1': 'str',\n",
    "    'P103_2': 'str',\n",
    "    'P103_3': 'str',\n",
    "    'P104_1': 'str',\n",
    "    'P104_4_CCEE': 'str',\n",
    "    'P105': 'str',\n",
    "    'P106': 'str',\n",
    "    'P109_1': 'str',\n",
    "    'P109A_1': 'str',\n",
    "    'P109C_1': 'str',\n",
    "    'P109D_1': 'str',\n",
    "    'P109_2': 'str',\n",
    "    'P109A_2': 'str',\n",
    "    'P109C_2': 'str',\n",
    "    'P109D_2': 'str',\n",
    "    'P109_3': 'str',\n",
    "    'P109C_3': 'str',\n",
    "    'P109D_3': 'str',\n",
    "    'P110': 'str',\n",
    "    'P110A': 'str',\n",
    "    'P110B': 'str',\n",
    "    'P110C': 'str',\n",
    "    'P111': 'str',\n",
    "    'P112': 'str',\n",
    "    'P113_1': 'str',\n",
    "    'P113_2': 'str',\n",
    "    'P113_3': 'str',\n",
    "    'P113_4': 'str',\n",
    "    'P113_5': 'str',\n",
    "    'P113_6': 'str',\n",
    "    'P113A_1': 'str',\n",
    "    'P113A_2': 'str',\n",
    "    'P113A_3': 'str',\n",
    "    'P113A_4': 'str',\n",
    "    'P113A_5': 'str',\n",
    "    'P113A_6': 'str',\n",
    "    'P114': 'str',\n",
    "    'P114A_NO': 'str',\n",
    "    'P115': 'str',\n",
    "    'P117': 'str',\n",
    "    'P118': 'str',\n",
    "    'P119_1': 'str',\n",
    "    'P119_2': 'str',\n",
    "    'P119_3': 'str',\n",
    "    'P119_4': 'str',\n",
    "    'P119_5': 'str',\n",
    "    'P119_6': 'str',\n",
    "    'P120': 'str',\n",
    "    'P121': 'str',\n",
    "    'P122_NO': 'str',\n",
    "    'P123_1': 'str',\n",
    "    'P123_2': 'str',\n",
    "    'P123_3': 'str',\n",
    "    'P123_4': 'str',\n",
    "    'P123_5': 'str',\n",
    "    'P123_6': 'str',\n",
    "    'P124_NO': 'str',\n",
    "    'P125_1': 'str',\n",
    "    'P125_2': 'str',\n",
    "    'P125_3': 'str',\n",
    "    'P125_4': 'str',\n",
    "    'P125_5': 'str',\n",
    "    'P125_6': 'str',\n",
    "    'P126': 'str',\n",
    "    'P127': 'str',\n",
    "    'P128': 'str',\n",
    "    'P129': 'str',\n",
    "    'P130': 'str',\n",
    "    'P131': 'str',\n",
    "    'P132': 'str',\n",
    "    'P133': 'str',\n",
    "    'P135': 'str',\n",
    "    'P136': 'str',\n",
    "    'P137': 'str',\n",
    "    'P138': 'str',\n",
    "    'P139': 'str',\n",
    "    'P140': 'str',\n",
    "    'P141_1': 'str',\n",
    "    'P141_2': 'str',\n",
    "    'P141_3': 'str',\n",
    "    'P141_4': 'str',\n",
    "    'P141_5': 'str',\n",
    "    'P141_6': 'str',\n",
    "    'P141_7': 'str',\n",
    "    'P141_8': 'str',\n",
    "    'P141_9': 'str',\n",
    "    'P141_10': 'str',\n",
    "    'P141_11': 'str',\n",
    "    'P141_12': 'str',\n",
    "    'P141_13': 'str',\n",
    "    'P201_DD': 'str',\n",
    "    'P201_PP': 'str',\n",
    "    'P201_DI': 'str',\n",
    "    'P202': 'str',\n",
    "    'P203': 'str',\n",
    "    'P204': 'str',\n",
    "    'P205': 'str',\n",
    "    'P206': 'str',\n",
    "    'P207_NO': 'str',\n",
    "    'P208': 'str',\n",
    "    'P209': 'str',\n",
    "    'P210': 'str',\n",
    "    'P211': 'str',\n",
    "    'P212': 'str',\n",
    "    'P213': 'str',\n",
    "    'P214': 'str',\n",
    "    'P215': 'str',\n",
    "    'P216': 'str',\n",
    "    'P217': 'str',\n",
    "    'P217A': 'str',\n",
    "    'P218': 'str',\n",
    "    'P219': 'str',\n",
    "    'P219A_NO': 'str',\n",
    "    'P220': 'str',\n",
    "    'P301': 'str',\n",
    "    'P302': 'str',\n",
    "    'P303': 'str',\n",
    "    'P309': 'str',\n",
    "    'P310': 'str',\n",
    "    'P311_1': 'str',\n",
    "    'P311_2': 'str',\n",
    "    'P311_3': 'str',\n",
    "    'P311_4': 'str',\n",
    "    'P311_5': 'str',\n",
    "    'P311_6': 'str',\n",
    "    'P311_7': 'str',\n",
    "    'P311_8': 'str',\n",
    "    'P311_9': 'str',\n",
    "    'P311_10': 'str',\n",
    "    'P313_1': 'str',\n",
    "    'P313_2': 'str',\n",
    "    'P313_3': 'str',\n",
    "    'P313_4': 'str',\n",
    "    'P313_5': 'str',\n",
    "    'P314': 'str',\n",
    "    'P315': 'str',\n",
    "    'P316': 'str',\n",
    "    'P317': 'str',\n",
    "    'P318': 'str',\n",
    "    'P319_1': 'str',\n",
    "    'P319_2': 'str',\n",
    "    'P319_3': 'str',\n",
    "    'P319_4': 'str',\n",
    "    'P319_5': 'str',\n",
    "    'P319_6': 'str',\n",
    "    'P402_NO': 'str',\n",
    "    'P403_1': 'str',\n",
    "    'P403_2': 'str',\n",
    "    'P403_3': 'str',\n",
    "    'P403_4': 'str',\n",
    "    'P403_5': 'str',\n",
    "    'P403_6': 'str',\n",
    "    'P403_7': 'str',\n",
    "    })\n",
    "\n",
    "    # Guardar el conjunto de datos limpio\n",
    "    data.to_csv('DATA6.csv', index=False, encoding='utf-8')\n",
    "    print(\"\\nDatos limpiados y guardados en 'DATA6.csv'\")\n",
    "else:\n",
    "    print(\"No se pudo cargar el archivo CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUEST_NRO     int32\n",
       "DD           object\n",
       "PP           object\n",
       "DI           object\n",
       "CP           object\n",
       "              ...  \n",
       "P403_3       object\n",
       "P403_4       object\n",
       "P403_5       object\n",
       "P403_6       object\n",
       "P403_7       object\n",
       "Length: 200, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
